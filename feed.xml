 <?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Brandon Rohrer</title>
  <link>https://www.brandonrohrer.com</link>
  <image>
    <url>http://e2eml.school/images/transformers/architecture_multihead.png</url>
    <title>Blog</title>
    <link>https://www.brandonrohrer.com</link>
  </image>
  <description>Brandon Rohrer's blog, articles, and books</description>

  <item>
    <title>Blog post: Ten Tips for Working with Numba</title>
    <link>https://brandonrohrer.com/numba</link>
   <description>
Vectorization with NumPy is an indispensable tool for working with data and algorithms, but sometimes even that isn't quite fast enough. If you have deep pockets and the patience of a saint, you can get your code running on GPUs, but for most of us, Numba is the secret to unlocking performance. Here are some tricks I've collected.

    1. Try for-loops first. Set aside all your hard-won intuitions about vectorization. They don't apply within a Numba function.
    
    2. Avoid using NumPy array operations or using NumPy functions. Modify one element at a time using common operators. Undo all your vectorization.
    
    3. Don't create intermediate NumPy arrays in your Numba code. Those get allocated and written, which takes extra time.
    
    4. Don't write your own matrix multiplication. (Unless it's for fun.)
    
    5. Use @njit rather than @jit. This will prevent your function from failing silently and slowing down to interpreted Python.
    
    6. Call Numba-jitted functions once before kicking off the program. This "warms them up" by forcing the compiler to compile them on the first time through.
    
    7. Pass return variables in as input arguments. That way the memory space for them is pre-allocated.
    
    8. Declare array arguments and created arrays with an explicit data type (usually numpy.float). This will prevent cryptic error messages later.
    
    9. Profile your code line by line. Only use Numba where it really makes a difference.
    
    10. Build Numba functions incrementally, testing often.
</description>
  </item>


  <item>
    <title>Naive Cartographer: A Markov Decision Process Learner</title>
    <link>https://codeberg.org/brohrer/cartographer-paper/raw/branch/main/cartographer.pdf</link>
   <description>
   tl;dr: A naive Bayes algorithm for learning Markov de-
cision processes with fuzzy state

x Fuzzy Naive Cartographer (FNC) builds a Markov Decision Process-like model of
its world in the form of a set of sequences. Sequences are of the form of
state-action-state as in MDPs. Here they're also referred to as
feature-action-outcome sequences, to disambiguate the before- and after-state.

FNC builds a value function too. It creates a set of feature-action pairs
and associates a reward with each. This is analogous to the state-action
value functions of Q-learning.

A model and a value function allow for prediction and planning.
Knowing the current active features and recent actions,
both the reward and the resulting features can be anticipated.

Technically FNC is just the "model" part of a model-based RL algorithm.
It needs to paired with a planner, some element that will choose
an action or goal, to be a complete RL algorithm.
There are some rudimentary planners included with this module to get you up and running.

Repository: https://codeberg.org/brohrer/ziptie

White paper: https://codeberg.org/brohrer/cartographer-paper/raw/branch/main/cartographer.pdf
</description>
  </item>


</channel>

</rss> 
